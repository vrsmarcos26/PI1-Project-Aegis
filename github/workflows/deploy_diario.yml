name: Coleta de Dados e Deploy Automático

on:
  schedule:
    # Cron em UTC. 09:00 UTC = 06:00 Brasil | 21:00 UTC = 18:00 Brasil
    - cron: '0 9,21 * * *'
  # Permite rodar manualmente na aba Actions para testar
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  atualizar-e-publicar:
    runs-on: ubuntu-latest

    steps:
      - name: 1. Checkout do Repositório
        uses: actions/checkout@v4

      - name: 2. Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: 3. Instalar Dependências
        run: |
          pip install pandas requests

      - name: 4. Executar Scripts de Coleta
        env:
          # Injetando as chaves que você criou nos Secrets
          API_OTX: ${{ secrets.API_OTX }}
          API_ABUSEIPDB: ${{ secrets.API_ABUSEIPDB }}
          API_NVD_CVE: ${{ secrets.API_NVD_CVE }}
        run: |
          echo "Iniciando coletas..."
          # Como estamos na raiz, chamamos src/scripts/arquivo.py
          # Eles vão salvar os JSONs dentro da pasta 'site/'
          python src/scripts/coletor_otx.py
          python src/scripts/coletor_paises.py
          python src/scripts/coletor_cve.py
          python src/scripts/coletor_vazamentos.py
          echo "Coletas finalizadas!"
          
          # Listar a pasta site para confirmar que os JSONs estão lá (Debug)
          ls -l site/

      - name: 5. Configurar GitHub Pages
        uses: actions/configure-pages@v4

      - name: 6. Upload do Site (Artefato)
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'site/' # Publica APENAS a pasta site (html + js + jsons novos)

      - name: 7. Deploy para GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4